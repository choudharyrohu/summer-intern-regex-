{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e7c185f8",
   "metadata": {},
   "source": [
    "1 )diference between machine learnig and deep  learning\n",
    "2) why we use optimizers\n",
    "3) what does activation function in deep learning\n",
    "4) what is loss function and when we use binary catagorical \n",
    "cross entropy, sparse catgorical cross entropy,mean square, \n",
    "mean aboslute error\n",
    "5) what is dense layer and why it is called as fully connected layer\n",
    "6) what is differece between CNN and ANN\n",
    "7) what is pretrained model in CNN\n",
    "8) what is stride and padding in CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752157f3",
   "metadata": {},
   "source": [
    "8) what is stride and padding in CNN\n",
    "Stride\n",
    "Stride is the number of pixels the filter moves across the input image.\n",
    "Stride of 1: Moves one pixel at a time, leading to a larger output.\n",
    "Stride of 2 or more: Moves two or more pixels at a time, leading to a\n",
    "smaller output\n",
    "\n",
    "Padding\n",
    "Padding adds extra pixels (usually zeros) around the input image.\n",
    "No Padding (Valid): No extra pixels are added, which reduces the \n",
    "output size.\n",
    "Same Padding: Pads the input so that the output size remains the sa\n",
    "me as the input size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afa51bb",
   "metadata": {},
   "source": [
    "7) what is pretrained model in CNN\n",
    "A pretrained model in CNN is a neural network model that has been previously trained\n",
    "on a large dataset, often for a specific task like image classification. Instead\n",
    "of training a model from scratch, you can use a pretrained model and either:\n",
    "Directly use it for tasks similar to what it was trained on.\n",
    "Fine-tune it by further training on a different but related task with your own dataset.\n",
    "Pretrained models save time and resources and often perform better due to the knowledge gained from the initial training. Examples include VGG, ResNet, and Inception models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a5d49",
   "metadata": {},
   "source": [
    "6) what is differece between CNN and ANN\n",
    "Structure\n",
    "CNNs: Utilize convolutional layers, pooling layers, and often fully connected layers. \n",
    "They are designed to automatically and adaptively learn spatial hierarchies of features from input images.\n",
    "ANNs: Consist of layers of neurons, typically fully connected, where each neuron in \n",
    "one layer connects to every neuron in the next layer. They are more general-purpose and do not specifically take advantage of the spatial structure in data.\n",
    "\n",
    "\n",
    "Application\n",
    "CNNs: Primarily used for image and video recognition, image classification, object detection, \n",
    "and other tasks involving spatial data.\n",
    "ANNs: Used for a variety of tasks, including classification, regression, and pattern recognition, \n",
    "but they are not as effective for image-related tasks compared to CNNs.\n",
    "\n",
    "\n",
    "Key Feature\n",
    "CNNs: Use convolutional operations to detect local patterns and features, making them particularly \n",
    "powerful for processing grid-like data such as images.\n",
    "ANNs: Rely on fully connected layers and are more suited for tasks where spatial hierarchies and \n",
    "local patterns are less relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f2126",
   "metadata": {},
   "source": [
    "5) what is dense layer and why it is called as fully connected layer\n",
    "A dense layer, also known as a fully connected layer, is a layer in a neural network where each \n",
    "neuron is connected to every neuron in the previous layer.\n",
    "\n",
    "Key Points:\n",
    "Fully Connected: Every neuron in the dense layer receives input from all neurons of the previous layer, \n",
    "hence the term \"fully connected.\"\n",
    "Function: It performs a weighted sum of the inputs and applies an activation function, \n",
    "which helps in learning complex patterns and representations.\n",
    "Dense layers are typically used at the end of CNN architectures to combine features learned by \n",
    "convolutional and pooling layers and make final predictions.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5c23b4e",
   "metadata": {},
   "source": [
    "Certainly! Below is a table that outlines the differences between Machine Learning (ML) and Deep Learning (DL):\n",
    "\n",
    "| Aspect                  | Machine Learning (ML)                                      | Deep Learning (DL)                                           |\n",
    "|-------------------------|------------------------------------------------------------|--------------------------------------------------------------|\n",
    "| Definition              | A subset of artificial intelligence focused on algorithms that allow computers to learn from data and make decisions based on it. | A subset of machine learning that uses neural networks with many layers to model complex patterns in large datasets. |\n",
    "| Data Dependencies       | Can work with smaller datasets and structured data.        | Requires large amounts of data, often unstructured, for effective training. |\n",
    "| Feature Engineering     | Requires significant manual feature engineering.           | Automatically discovers features from raw data, minimizing the need for manual feature engineering. |\n",
    "| Algorithms              | Includes methods like linear regression, decision trees, random forests, support vector machines, etc. | Primarily involves various architectures of neural networks such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and Transformers. |\n",
    "| Computational Power     | Typically requires less computational power compared to DL. | Requires high computational power, often utilizing GPUs and TPUs. |\n",
    "| Training Time           | Generally shorter training times.                          | Can have significantly longer training times due to complex model architectures. |\n",
    "| Interpretability        | Often more interpretable and easier to understand.         | Usually less interpretable, often seen as a \"black box\" due to complex layers. |\n",
    "| Applications            | Used in applications like spam detection, recommendation systems, and predictive maintenance. | Used in more complex applications like image and speech recognition, natural language processing, and autonomous driving. |\n",
    "| Model Complexity        | Models are typically simpler and less complex.             | Models are deep and complex with many layers. |\n",
    "| Scalability             | Easier to implement and scale for different tasks with moderate complexity. | Scaling can be more challenging due to high computational and data requirements. |\n",
    "\n",
    "These differences highlight how ML and DL cater to different types of problems and requirements in the field of artificial intelligence."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9004609b",
   "metadata": {},
   "source": [
    "2) why we use optimizers\n",
    "\n",
    "Optimizers are used in Machine Learning (ML) and Deep Learning (DL) to minimize the loss function by adjusting the model's parameters. This process improves the model's accuracy and performance. Here’s a brief overview:\n",
    "\n",
    "1. *Gradient Descent*: Optimizers like gradient descent update the weights in the direction that reduces the loss, ensuring the model learns from errors.\n",
    "2. *Efficiency*: They help in efficiently navigating the error surface, speeding up the convergence to the optimal solution.\n",
    "3. *Avoiding Local Minima*: Advanced optimizers like Adam, RMSprop, and others help avoid local minima and saddle points, leading to better performance.\n",
    "\n",
    "In essence, optimizers are crucial for training models effectively and achieving better results."
   ]
  },
  {
   "cell_type": "raw",
   "id": "26327324",
   "metadata": {},
   "source": [
    "\n",
    "3)what does activation function in deep learning\n",
    "\n",
    "In Deep Learning (DL), an activation function is a mathematical function applied to each neuron in a neural network. It determines whether a neuron should be activated or not based on the input it receives. Here’s a simple explanation:\n",
    "\n",
    "1. *Non-linearity*: Activation functions introduce non-linearity into the network, enabling it to learn complex patterns. Without them, the network would behave like a linear regression model, no matter how many layers it has.\n",
    "   \n",
    "2. *Output Transformation*: They transform the input signal of a neuron, which helps the network to make sense of complicated data and perform tasks like classification, regression, and more.\n",
    "\n",
    "Common activation functions include:\n",
    "- *ReLU (Rectified Linear Unit)*: Outputs the input directly if it's positive; otherwise, it outputs zero.\n",
    "- *Sigmoid*: Squashes the input to be between 0 and 1.\n",
    "- *Tanh*: Squashes the input to be between -1 and 1.\n",
    "\n",
    "In summary, activation functions are essential in DL as they allow neural networks to model complex data and perform various tasks effectively."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0072829b",
   "metadata": {},
   "source": [
    "4) what is loss function and when we use binary catagorical \n",
    "cross entropy, sparse catgorical cross entropy,mean square, \n",
    "mean aboslute error\n",
    "\n",
    "In simple terms, a loss function in Machine Learning (ML) and Deep Learning (DL) is a measure of how well a model's predictions match the actual data. It quantifies the difference between the predicted values and the true values, guiding the optimization process during training to improve the model. Different types of loss functions are used for different types of tasks:\n",
    "\n",
    "1. *Binary Cross Entropy*:\n",
    "   - *Used for*: Binary classification tasks (e.g., distinguishing between two classes, like spam vs. not spam).\n",
    "   - *Function*: Measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
    "\n",
    "2. *Categorical Cross Entropy*:\n",
    "   - *Used for*: Multi-class classification tasks where each sample belongs to one of many classes (e.g., classifying images of animals into categories like cats, dogs, and horses).\n",
    "   - *Function*: Compares the predicted probability distribution over classes with the actual distribution, assuming the actual labels are one-hot encoded (only one class is correct).\n",
    "\n",
    "3. *Sparse Categorical Cross Entropy*:\n",
    "   - *Used for*: Similar to categorical cross entropy but for tasks where the actual labels are integers rather than one-hot encoded vectors.\n",
    "   - *Function*: Works directly with integer labels, which can be more efficient for large classification tasks.\n",
    "\n",
    "4. *Mean Squared Error (MSE)*:\n",
    "   - *Used for*: Regression tasks (e.g., predicting a continuous value like house prices).\n",
    "   - *Function*: Calculates the average of the squared differences between predicted values and actual values. It penalizes larger errors more heavily.\n",
    "\n",
    "5. *Mean Absolute Error (MAE)*:\n",
    "   - *Used for*: Regression tasks.\n",
    "   - *Function*: Calculates the average of the absolute differences between predicted values and actual values. It treats all errors equally regardless of their size.\n",
    "\n",
    "In summary, these loss functions are chosen based on the type of problem (classification or regression) and the nature of the output and labels (binary, categorical, or continuous). They help the model learn by providing a metric to minimize during training.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
