{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a3dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a9ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Documents\\\\Summer internship\\\\Deep Learning\\\\IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdb5231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9572ae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2767d",
   "metadata": {},
   "source": [
    "# Step 1 Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e959d485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a333a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd21f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676ffa26",
   "metadata": {},
   "source": [
    "# Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e2fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern=re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594b7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text = \"<html><body><p> Movie1 </p><p> Click here to <a href = 'http://google.com'>download</a></p> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b2bb7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Movie1  Click here to download '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade96506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0b05553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'' , text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "247e3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "text1 = 'Check out my notebook https://www.deture.com/delta/note1234acc'\n",
    "\n",
    "text2 = 'Check out my notebook https://www.deture.com/delta/note1234acc'\n",
    "\n",
    "text3 = 'Google search here www.google.com'\n",
    "\n",
    "text4 = 'For notebook click https://www.deture.com/delta/note1234acc'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b1a73c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For notebook click '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c42d037",
   "metadata": {},
   "source": [
    "# Step 4 Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0338c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import time\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26b352ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0961ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "957f2a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1='string. with .??'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd3c5db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'string  with    '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_punc(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "584fb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c7e2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Documents\\\\Summer internship\\\\Deep Learning\\\\twitter_sentiment_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10f153fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production  the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei s  love in the time of money  is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot  bad dialogue  bad acting  idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i m going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production  the filming tec...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there s a family where a little boy ...  negative\n",
       "4      petter mattei s  love in the time of money  is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot  bad dialogue  bad acting  idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i m going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30c55dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "184b59f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de044fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['tweet']=df2['tweet'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6802d036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>user  white  supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your  acne       altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd  bihday to my amazing  hilarious  nephew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory  left right polarisation   tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð  hairflip  neverre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>hillary  campaigned today in  ohio  omg    am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy  at work conference  right mindset leads...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song  so glad  free download    shoegaze ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet\n",
       "0      31963   studiolife  aislife  requires  passion  dedic...\n",
       "1      31964    user  white  supremacists want everyone to s...\n",
       "2      31965  safe ways to heal your  acne       altwaystohe...\n",
       "3      31966  is the hp and the cursed child book up for res...\n",
       "4      31967    3rd  bihday to my amazing  hilarious  nephew...\n",
       "...      ...                                                ...\n",
       "17192  49155  thought factory  left right polarisation   tru...\n",
       "17193  49156  feeling like a mermaid ð  hairflip  neverre...\n",
       "17194  49157   hillary  campaigned today in  ohio  omg    am...\n",
       "17195  49158  happy  at work conference  right mindset leads...\n",
       "17196  49159  my   song  so glad  free download    shoegaze ...\n",
       "\n",
       "[17197 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7fb11b",
   "metadata": {},
   "source": [
    "# step 5 Chatword Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a461a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words = {'u2' : 'you too' , 'BBL': 'Be Back Later' , 'GAL': 'Get A Life'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "689c9c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u2': 'you too', 'BBL': 'Be Back Later', 'GAL': 'Get A Life'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "284c9085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversation(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words :\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else :\n",
    "            new_text.append(w)\n",
    "\n",
    "    return \"\".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1002b1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get A Life'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversation('GAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea181f1",
   "metadata": {},
   "source": [
    "# Step 6 Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2fbe5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d79de35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions several generations are modified in the same manner.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_text = \"ceertain conditionas seveal ggenerations aree modified in the saame maner.\"\n",
    "\n",
    "textBlb = TextBlob(incorrect_text)\n",
    "\n",
    "textBlb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e7340",
   "metadata": {},
   "source": [
    "# Step 7 Removing StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "82913ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee5197f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7bf6b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c44509a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'probablyall-timefavoritemovie,storyselflessness,sacrificededicationnoblecause.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # manully works\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "\n",
    "    for word in text.split():\n",
    "\n",
    "        if word in set(stopwords.words('english')):\n",
    "            new_text.append(\"\")\n",
    "\n",
    "        else :\n",
    "            new_text.append(word)\n",
    "\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return \"\".join(x)\n",
    "\n",
    "remove_stopwords('probably my all-time favorite movie , a story of selflessness ,sacrifice and dedication to a noble cause.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11404ab1",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7636fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prefix - character(s) at the begining = $(\" .)\n",
    "\n",
    "# 2. suffix - character(s) at the end = km) .! \"\n",
    "\n",
    "# 3. Infix - character(s) in between = -- / ...\n",
    "\n",
    "# 4. Exception - Special-case rule to split a string into several tokens or\n",
    "# prevent a token from being split when punctuation rules are applied . = let's U.s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f2600cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Approach the tokenization using the split function\n",
    "\n",
    "# 1. word tokenization\n",
    "\n",
    "sent1 = \"I am going to delhi\"\n",
    "sent1.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3135070c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi ',\n",
       " ' I will stay there for 3 days',\n",
       " \" Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = \"I am going to delhi . I will stay there for 3 days. Let\\'s hope the trip to be great\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db230bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = \"I am going to delhi!\"\n",
    "sent3.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f15184de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am going to delhi'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sent3 = \"I am going to delhi\"\n",
    "tokens = re.findall(\"[\\w']+\", sent3)\n",
    "sent3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5679de9c",
   "metadata": {},
   "source": [
    "# 1 NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2803e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize , sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "199e0c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "15bf4a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'visit', 'delhi', '!']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = \"I am going to visit delhi!\"\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc1b1c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D.', 'in', 'A.I', '.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2 = 'I have a Ph.D. in A.I.'\n",
    "sent3 = \"We 're here to help! mail us at nks@gmail.com \"\n",
    "sent4 = 'A 5km ride cost $10.50'\n",
    "\n",
    "word_tokenize(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78edf382",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b072b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Inflection == > \"In grammar , inflection is the modification of a word\n",
    "# to express different grametical categories such as tense , case , voice , aspect , person ,\n",
    "# humber , gender and mood .\"\n",
    "\n",
    "# 2. Stemming == > Stemming is the process of reducing inflection in words to their root forms\n",
    "# such as mapping a group of words to the same stem even if the stem itself is not valid\n",
    "# word in the Language ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "774e2f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43e81209",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e891fc5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d19ebba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probably my alltime favourite movie a story of selflessness sacrifice and dedication.\n"
     ]
    }
   ],
   "source": [
    "# stemming mapping a group pf words to the same stem even if the stem itself is not valid word in La\n",
    "\n",
    "text = 'probably my alltime favourite movie a story of selflessness sacrifice and dedication.'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82c453aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So , we have to use Lemmatization instead of stemming .\n",
    "\n",
    "# note - stemming is fast and Lemmatization is slow ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a5e3c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization , unlike Stemming , reduces the inflected words properly ensuring that\n",
    "# the root word belongs to the Language .\n",
    "# In Lemitization root word is called Lemma . I\n",
    "# Alemma (plural Lemmas or Lemmata) is the canonical form , dictionary form , or citation form\n",
    "# of a set of words .\n",
    "\n",
    "# Stemming works on beehalf algorithm , so it is fast and lemmatization is using wordnet package ,\n",
    "# so it's slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "313b15bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2e24bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14fe8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "was                 wa                  \n",
      "and                 and                 \n",
      "at                  at                  \n",
      "same                same                \n",
      ".                   .                   \n",
      "has                 ha                  \n",
      "habbit              habbit              \n",
      "swimming            swimming            \n"
     ]
    }
   ],
   "source": [
    "sentence = 'He was running and eating at the same time . He has bad habbit of swimming after'\n",
    "punctuation = ' ?:!. ,;'\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    sentence_words.remove(word)\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\" , \"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word , wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef80de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
